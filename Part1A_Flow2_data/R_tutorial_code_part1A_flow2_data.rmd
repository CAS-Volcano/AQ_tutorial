Title: "Part 1A Flow 2"

Author: "Hans de Leeuw and Martin Rogers"

Date: "10/02/2021"

This is a R markdown file that serves as an example on how to read in Flow 2 instrument data and plot a simple timeseries.
 
The program contains sections on:  

- Importing the required R packages
- How to read in the Air Quality (AQ) data from the Flow 2 instrument
- Plot a timeseries of the AQ data
- Plotting a map with the location of the Flow 2 instrument
- Saving the figures
- Some basic statistics examples

```{r set working directory, include=FALSE}
## You'll need to set your working directory below, i.e. the folder where your data files are stored.
setwd("C:/")
```

Just like you need to get all the tools before you can start painting a picture (brushes, paper, paint, etc), we also need to get the all the tools for plotting and analysing data in R. In R these are called 'packages' and each package has a set of premade functions and codes that will help us to analyse and plot the AQ data. In the list below we have imported many packages that we will use (with a short description added to explain what they are used for).
```{r load packages, include=FALSE}
# Load relevant libraries (install package first)
if (!"sf" %in% installed.packages()) install.packages("sf")
library(sf) #for converting databases into a 'format' which can be plotted on a map
if (!"sp" %in% installed.packages()) install.packages("sp")
library(sp) #for converting databases into a 'format' which can be plotted on a map
if (!"tmap" %in% installed.packages()) install.packages("tmap")
library(tmap) # for plotting static and interactive maps
if (!"zoo" %in% installed.packages()) install.packages("zoo")
library(zoo) #for calculating basic statistics e.g. rolling mean
```

We'll be making use of the following packages:
```{r message=FALSE}
library(sf)
library(sp)
library(tmap) 
library(rgdal)
```

#### **Reading in the Flow 2 data**

Before we can start analysing the Flow 2 data we need to import it to the R environment. We use the first two example files given in the folder Part1A_Flow2_data : 1) user_measures_20200929_20201109_2.csv and 2) user_positions_20200929_20201109_2.csv.

When you will start collecting your own data the Flow 2 files will be of a similar structure, but much larger. Make sure to change the paths to the files and names of the files below to be able to look at the data.

```{r import datasets, view datasets and their dimensions}

df <- read.csv('user_measures_20200929_20201109_2.csv', header=TRUE)    # read in the measurement csv datafile (we call it df)
df2 <- read.csv('user_positions_20200929_20201109_2.csv', header=TRUE)  # read in the position csv datafile (we call it df2)

#View(df) #view dataset in seperate window. Remove hashtag to view. 
head(df) #view top 6 rows of dataset in console
dim(df) # calculate the dimensions of the imported dataset

```

Looking at the values above we see that the array has two dimensions (1273 and 12). To help you interpret these numbers, imagine that the array is a large chest of drawers, where the first number (1273) represents the number of drawers (dimension) from top to botom (rows) and the second number (12) is the number the drawers from left to right (columns). Each combination of these 2 numbers within this range represent a specific drawer where we have stored a specific value. For example [2,10] is the drawer 10 in row 2 and these numbers will help us to identify the location where we have stored our data.

In our Flow 2 example, we have 1273 rows, each row represents a specific time (i.e. 24*60=1440 minutes per day, so almost a full day of data). In other words, each row of drawers represents the minute data and each variable is stored in a specific column of our chest of drawers. Let us have a look at the headers of each column, so that we know what data is stored:

```{r Find column names of the AQ data}
colnames(df)
```
NOTE: when importing the dataset, R converts paretheses and spaces into dots.
Therefore, the column headers in R differ slightly from those in the original .csv file.


#### **Plotting a timeseries of the AQ data**

Now that we know what data we have in our array, we can start plotting the data. Using R's built in dataframe functions, it is relatively easy to get a quick look at the data using the build in 'plot' function and the name of a specific column (use the full name as shown in the print statement above):


```{r Plotting a timeseries of the AQ data}
plot.ts(df['NO2..ppb.'], lwd=0.5)#plot time series (ts)
```

However this plot does not have any information on what is plotted on the axis, does not look that nice and so we need to work on the plot to make it more presentable. For example we need to add a label to the y-axis and convert the x-axis to represent the time, rather than the index of the row (1273 timesteps). To do this the first thing we need to do is to make the x-axis a date rather than the input row number. This is done by changing the format of the "date (UTM)" column to datetime and then changing the index (or rowname) of our df array based on the date column:


```{r Make the date time column the index of the dataframe}
#convert date column to datetime format
df$date..UTC. <- as.POSIXct(x = as.character(df$date..UTC.),
                                format = "%d/%m/%Y %H:%M", tz='UTC')

#change index of our df array based on the date column
rownames(df)<-df[ , "date..UTC."]

#View(df)# remove hashtag to view how df array has changed
```

Now we can plot with the x axis in dateTime format. We have to manually set the start and end time and the values of tick marks (breaks) on the x-axis. 
```{r plot using datetime on x axis}

start <- trunc(min(df$date..UTC.), "mins") #First date value
end <- trunc(max(df$date..UTC.), "mins")#Last date value

#Calculate the time values for all ticks on the x axis. In this case, 
#we want 5 ticks, including the start time and end time. 
breaks <- round(seq(start, end,length.out = 5), "hours")

#create the plot- using (date, NO2) as the (x,y) values respectively. 
#xaxt='n' removes the x axis, so that we can fine tune its parameters using the axis.POSIXct() line
plot(df["date..UTC."], df[, 'NO2..ppb.'],type='l', xaxt='n',
     col=4, lty= 1,lwd=1,
     xlab='Time (UTC)', ylab=expression('NO'[2]*' Concentrations (ppb)'),
     main=expression('Times series of 30 September 2020 NO'[2]*' concentrations (ppb)'),
     cex.main=0.8)

#Fine tune the values on the x-axis.
#1=x axis, 2=y axis.
#at= tick values to use (in this case the break values we calculate above)
#format- this ensures only hour and minutes are shown
axis.POSIXct(1, at=breaks, format="%H:%M")

```

##### **Tasks**
Task 1- What do the 'col', 'lty', 'lwd' and 'cex.main' values do in the plot() function?
experiment with changing their numeric values. 

Task 2- what happens if you hashtag out the axis.POSIXct() line?

Yay, we have succesfully plotted a timeseries of the data with correct axes and a title!
We may only be interested in a particular subset of the dataset, e.g. only the datapoints collected between 00:00 and 12:00 on 2020-09-30. The best way to plot this graph is to first make a new dataframe, df_sub, which only contains the rows of the dataset corresponding to our timeframe of interest.

```{r Subset dataset}
df_sub<-df[which(rownames(df)=='2020-09-30 00:00:00'):which(rownames(df)=='2020-09-30 12:00:00'), ]
#View(times_subset)

#Create new breaks so subset has 5 ticks
start_sub <- trunc(min(df_sub$date..UTC.), "mins") #First date value
end_sub <- trunc(max(df_sub$date..UTC.), "mins")#Last date value
breaks_sub <- round(seq(start_sub, end_sub,length.out = 5), "hours")

dim(df_sub)# original dataset has dimensions (1273, 12).
```

So, all the 12 columns have been retained in df_sub, but only 656 rows correspond to our timeframe of interest.  

We can now plot NOC concentrations within this timeframe of interest in exactly the same way as before, but now using df_sub instead of df. 

We can also try to add an additional dataset to this figure, so that we can compare the NO2 concentrations to VOC concentrations.

Now we add one line to the plot we made above to have the second dataset in the figure:
```{r Plot subset dataset}

#Plot NO2 as before. NOTE- we are now using df_sub instead of df.
plot(df_sub[,'date..UTC.'], df_sub[,'NO2..ppb.'], type='l',col=4, lty= 1,lwd=2, ylim=c(0,1600),
     xlab='Time (UTC)', ylab=' Concentrations (ppb)',xaxt='n',
     main=expression('Times series of 30 September 2020 NO'[2]*' and VOC concentrations (ppb)'), cex.main=0.8)

#add additional VOC timeseries using lines()
lines(df[,"date..UTC."], df[, 'VOC..ppb.'],type='l', col=2)

#fine tune x axis
axis.POSIXct(1, at=breaks_sub, format="%H:%M")#add x axis

#input legend
legend("topleft", inset=0.05, legend=c(expression("NO"[2]*" (ppb)"), "VOC (ppb)"), 
       col=c(4,2), lty= 1, cex=1)

```

We see that the two datasets show very different ranges during the first 12 hours, which can make it difficult to interpret the data. Instead, we could also plot the two datasets above and below each other in different panels. This is done using the following command:


```{r Make two plots, one on top of the other}
#We use the par function to define the number of rows (2) and columns (1) we want on our new plot.
par(mfrow=c(2,1))

#top plot
plot(df_sub[,'date..UTC.'], df_sub[,'NO2..ppb.'], type='l',col=4, lty= 1,lwd=2,
     ylim=c(0,60),xlab='Time (UTC)', ylab=expression('NO'[2]*' Concentrations (ppb)'),
     main=expression('Times series of 30 September 2020'), cex.main=1.0, xaxt='n')

axis.POSIXct(1, at=breaks_sub, format="%H:%M")#add x axis
#bottom plot
plot(df_sub[,'date..UTC.'], df_sub[,'VOC..ppb.'], type='l',col=2, lty= 1,lwd=2,
     ylim=c(0,1400),xlab='Time (UTC)', ylab=expression('VOC Concentrations (ppb)'),
     main=expression('Times series of 30 September 2020'), cex.main=1.0, xaxt='n')
axis.POSIXct(1, at=breaks_sub, format="%H:%M")#add x axis
```


Plotting the two figures independently as we have done above, we see that there are several issues:

- Each graph is quite small, to increase the size of the graphs we can reduce the size of the margins using the par(mar=c(bottom, left,top, right)) function. This sets the size of each margin independently. 
- We only need one x-axis title, (the x-axis title is removed from the top graph)
- There are issues with both axes, (we remove the x and the y axes using yaxt='n' and xaxt='n' in the plot() functions and then use the axis() function).
- The y-axis labels are too close to each other, (so we reduce the font size using cex.axis and rotate them using las=2). 
- We only need the x-axis tick labels on one graph, (we remove these labels from the top graph using label=FALSE but retain the ticks using tck=0.05 in the axis.POSIXct() function). 
- We don't know which line represents which variable (adding legend to each plot).

We can fix these by adding the following lines to the figure:
```{r Resolving issues with stacked plot}

par(mfrow=c(2,1))
par(mar=c(1,4,3,2))#margin size

#top plot
plot(df_sub[,'date..UTC.'], df_sub[,'NO2..ppb.'], type='l',col=4, lty= 1,lwd=2, ylim=c(0,50), xlab=NULL,
     ylab=expression('NO'[2]*' Concentrations (ppb)'),xaxt="n", yaxt='n',
     main=expression('Times series of 30 September 2020'), cex.main=0.8, cex.lab=0.8)

axis.POSIXct(1, at=breaks_sub, labels= FALSE, tck=0.05, cex=0.8)#add x axis
axis(2, cex.axis=0.8, las=2)#add y axis.
legend("topleft", inset=0.05, legend=expression("NO"[2]*" (ppb)"), 
       col=4, lty= 1, cex=0.8)#add legen

#bottom plot
par(mar=c(3.9,4,0.4,2))
plot(df_sub[,'date..UTC.'], df_sub[,'VOC..ppb.'], type='l',col=2, lty= 1,lwd=2,
     ylim=c(0,1500), xaxt= 'n', yaxt='n',
     xlab='Time (UTC)', ylab=expression('VOC Concentrations (ppb)'), cex.lab=0.8)

axis.POSIXct(1, at=breaks_sub, format="%H:%M")#add x axis
axis(2, cex.axis=0.8, las=2 )#add y axis
legend("topleft", inset=0.05, legend="VOC (ppb)", 
       col=2, lty= 1, cex=0.8)#add legend
```

#### **Plotting a map**

Another application of the data is to actually plot the location of the Flow2 measurements on top of a map. To do this we will need to use the location data that we stored in the df2 dataframe (see start of the document). Let us start by looking at what is stored in this dataframe:
```{r dataset 2}
df2 <- read.csv('user_positions_20200929_20201109_2.csv', header=TRUE)

df2$date <- as.POSIXct(x = as.character(df2$date),
                                format = "%d/%m/%Y %H:%M")
#View(df2)
colnames(df2)

```
Here we see that this array contains both the date and the corrensponding latitude and longitude. Let us see if we can actually plot this data on a map. First lets use the standard plot() function to get a feel of the relative positions of the data points. 

```{r first plot of coordinates}
firstPlot<-plot( df2$longitude,df2$latitude, ylab="Latitude", xlab="Longitude")
```

Now we can plot the datapoints onto an interactive map. For this we use the R tmap package. 
We first need to convert our data.frame *df2* into a spatial *sf* data.frame- called *df2_sf*

We need to also set the coordinate reference system (CRS)

Below the zoom buttons, you can click on the buttom to choose the different background layer e.g. OpenStreetMap. You can also pan and zoom on the interactive map using your mouse. 

NOTE: Do not worry about the warnings produced below.

```{r plot onto streetmaps}
tmap_mode('view') # view or plot
df2_sf <- st_as_sf(df2, coords = c( 'longitude', 'latitude'), crs=27000)
tm_shape(df2_sf) +tm_bubbles(size = 0.1, col = "blue")

```
##### **Task- Experiment with changing the 'size' and 'col' variables in tm_bubbles**

Investigating the timeseries of VOC, we see that there is a strong peak at some point between 8 am and 9 am. We might want to know where on the map these values are measured. To do this, we first try to identify the timing of the peak:

```{r Finding time of maximum VOC concentration}
#Locate the maximum VOC value
max_value<-apply(df['VOC..ppb.'], 2, max, na.rm=TRUE)
max_value #1490
# determine the time for which we measured the maximum value
which(df['VOC..ppb.'] == max_value, arr.ind = TRUE)

```
Now we try to understand where this measurement was taken by selecting this time in the location datafile:
```{r Finding longitude of maximum VOC measurement}
#numeric (0) means that the array is empty, showing us that we have no latitude/longitude data for this particular time.
df2$longitude[df2$date=='2020-09-30 08:26:00']
```
We see that the array is empty (because the output is 'numeric(0)'), showing us that we have no latitude/longitude data for this particular time. This shows you that doing this type of measurements can lead to uncomplete datasets and make it more complex to do our analysis. When you will do your own measurements, you will most likely have some gaps in your data that make analysing your data more challenging. What would be a possible solution for our current problem? We can select all the points between 8:11 and 8:48 to see if we have any lat/lon observations near this peak value:

```{r Subset dataframe by date}
peak_VOC<-df2[which(df2['date']=='2020-09-30 08:11:00'):which(df2['date']=='2020-09-30 08:48:00'),]

peak_VOC

```

This shows that we have 3 data points in this time period. Plotting these datapoints in red shows us the locations of these points:

```{r Plot these three datapoints in red}
tmap_mode('view') # view or plot
camVOC_sf <- st_as_sf(df2, coords = c( 'longitude', 'latitude'), crs=27000)
camVOC_sf_peak <- st_as_sf(peak_VOC, coords = c( 'longitude', 'latitude'), crs=27000)
tm_shape(camVOC_sf) +tm_bubbles(size = 0.0001, col = "blue") + tm_shape(camVOC_sf_peak) +tm_bubbles(size = 0.0001, col = "red")

```

#### **Saving the figure**

Now that we have some experience making figures, we want to be able save them so that we can add them to our reports, presentations, blog etc...

Before we show you how to save a figure, we first have to discuss two different types of save files (vector and raster images). Depending on your needs, you will have to pick the one that is most suitable for you. Lets start by describing the two:

#### **Raster images**

Raster images, as the name suggests, defines a grid (raster) and uses many colored pixels to form a complete image. JPEGs, GIFs and PNGs are common raster image types. Almost all of the photos found on the web and in print catalogs are raster images. Because raster images are constructed using a fixed number of colored pixels (Pixels per inch, also abbreviated as DPI), they canâ€™t be dramatically resized without compromising their resolution. When stretched to fit a space they werenâ€™t designed to fill, their pixels become visibly grainy and the image distorts. Therefore, it is important that you save raster files at precisely the dimensions needed to eliminate possible complications and also make sure you use a high enough DPI (e.g. 300 DPI is minimum requirement for most journals nowadays).

#### **Vector images**

Vector images are created using mathematical formulas rather than a grid. Common vector file types like EPS, AI and PDF are excellent for creating graphics that frequently require resizing. As a result of the vectorisation of your image, there is no decrease in sharpness when you resize your figures. The disatvantage of using vector images, is that the size of your figures can become huge, especially when you start to plot world maps etc. Therefore there is always a tradeoff between quality and figure size. Also when saving raster images with a very high dpi will get huge very fast, so don't overdo your dpi!

```{r saving figures}
#the file will automatically be saved in your working directory 
png(filename='Flow2_poster.png')
pdf(file="Flow2_poster.pdf")
par(mfrow=c(2,1))
par(mar=c(1,4,3,2))#margin size

#top plot
plot(df_sub[,'date..UTC.'], df_sub[,'NO2..ppb.'], type='l',col=4, lty= 1,lwd=2, ylim=c(0,50), xlab=NULL,
     ylab=expression('NO'[2]*' Concentrations (ppb)'),xaxt="n", yaxt='n',
     main=expression('Times series of 30 September 2020'), cex.main=0.8, cex.lab=0.8)

axis.POSIXct(1, at=breaks_sub, labels= FALSE, tck=0.05, cex=0.8)#add x axis
axis(2, cex.axis=0.8, las=2)#add y axis.
legend("topleft", inset=0.05, legend=expression("NO"[2]*" (ppb)"), 
       col=4, lty= 1, cex=0.8)#add legen

#bottom plot
par(mar=c(3.9,4,0.4,2))
plot(df_sub[,'date..UTC.'], df_sub[,'VOC..ppb.'], type='l',col=2, lty= 1,lwd=2,
     ylim=c(0,1500), xaxt= 'n', yaxt='n',
     xlab='Time (UTC)', ylab=expression('VOC Concentrations (ppb)'), cex.lab=0.8)

axis.POSIXct(1, at=breaks_sub, format="%H:%M")#add x axis
axis(2, cex.axis=0.8, las=2 )#add y axis
legend("topleft", inset=0.05, legend="VOC (ppb)", 
       col=2, lty= 1, cex=0.8)#add legend

dev.off()#this line is also needed to save the file
```
When you now check the folder you are currently working in, you will see the 2 saved files. As example I also created a low resolution Flow2_low.png file, to show you how important it is too have high quality figures! 


#### **Example 2: Plotting the timeseries of Second Flow 2 measurement (as shown in lecture notes)**

Just like we have done for the previous examples, we now read in a new set of Flow 2 measurements (we will call it 'df_lect'):
```{r Read in timeseries of second flow 2 measurements}
df_lect<-read.csv('user_measures_20201130_20201204_2.csv', header=TRUE)
df_lect$date..UTC. <- as.POSIXct(x = as.character(df_lect$date..UTC.),
                                format = "%Y-%m-%d %H:%M", tz='UTC')

head(df_lect)
dim(df_lect)
```
Looking at the values above we see that the array has two dimensions (4627 and 12). In this Flow 2 example, we have 4627 rows, each row represents a specific time (i.e. 24*60=1440 minutes per day, so a bit more than 3 days of data). Let us have a look at the headers of each column, so that we know what data is stored:

```{r Find column names of the data}
colnames(df_lect)
```
This shows that there it are the same species stored in this array as in our first example. This should make it easier for us to plot these values, as we already have the code. Let's plot the timeseries for the second of December 2020:

```{r Plot timeseries for December 2nd}
#Create dataframe corresponding to timeframe of interest
df_lect_sub<-df_lect[which(df_lect$date..UTC.=='2020-12-02 00:00:00'):which(df_lect$date..UTC.=='2020-12-03 00:02:00'), ]

plot(df_lect_sub$date..UTC., df_lect_sub$VOC..ppb., type='l', col= 4,
     ylab= "VOC concentrations (ppb)", xlab= "Time (UTC)", 
     main= "VOC concentrations (ppb) 2 December 2020", xaxt="n")

#set x-axis ticks for new timeframe
start_2 <- trunc(min(df_lect_sub$date..UTC.), "mins") #First date value
end_2 <- trunc(max(df_lect_sub$date..UTC.), "mins")#Last date value
breaks_2 <- round(seq(start_2, end_2,length.out = 5), "hours")

axis.POSIXct(1, at=breaks_2, format="%H:%M")#add x axis
grid(col='lightgray', lty='dotted', lwd=2)

```

Or we can also plot PM10 mass concentrations:

```{r Plot PM10 concentrations}
hist(df_lect_sub$pm.10..ug.m3., breaks=100, 
     ylab="Count",xlab=expression("Mass concentrations ("*mu*"g/m"^3*")"),
     main="Histogram of PM10 mass concentrations 2 December 2020", cex.main=1.0)

grid(col='lightgray', lty='dotted', lwd=1)
hist(df_lect_sub$pm.10..ug.m3., add=TRUE, breaks=100, col='blue', border= 'black')

box()#add box around graph

```

Now we see an anomalous high number of measurements in the first bin of our histogram. Let us have a closer look at the first bin of the data:

```{r Histogram PM10 concentrations}
with(df_lect_sub, hist(pm.10..ug.m3.[pm.10..ug.m3. >= 0 & pm.10..ug.m3. < 11],
                       breaks=seq(0,11,by=1),
                       col='blue', border= 'black', ylab="Count",xlim=c(0,10),
                       xlab=expression("Mass concentrations ("*mu*"g/m"^3*")"),
                       main="Histogram of PM10 mass concentrations 2 December 2020",
                       cex.main=1.0))

box()

```

From this first analysis we see that there is a large number of points where the mass concentration is 3  ðœ‡ g/m 3 . This is not realistic and seems to be the lower limit of the Flow 2 instrument or the default value when the Flow 2 did not make an observation. Therefore we should not use these values as we are not sure what they represent (actual values are unknown). Therefore we remove them from our dataset (make them NaN values (not a number) so that they can't be included as a values when we for example calculate mean values):

```{r Convert 3.0 to NaN}

df_lect_sub[,"pm.10..ug.m3."][df_lect_sub[, "pm.10..ug.m3."]==3.0]<-NA

```

So now that we removed some spurious data, let's try to plot the running mean values instead of all the minute data. This will give a smoother dataset that we can interpret better. In this example we calculate the rolling mean for each point using the 20 minutes before each point where we have data:
```{r calculate rolling mean}

rollapply(df_lect_sub['pm.10..ug.m3.'], 
          FUN=function(x) mean(x, na.rm=TRUE), width=20, fill=NA)


```


```{r  plotting rolling mean}

plot(df_lect_sub[,'pm.10..ug.m3.'], type='l',
     ylab= expression("Mass concentrations ("*mu*"g/m"^3*")"), 
     xlab= "Time (UTC)", main= "PM10 mass concentrations 2 December 2020")

grid(col='lightgray', lty='dotted', lwd=1)

lines(df_lect_sub[,'pm.10..ug.m3.'],
     type='l', col= 'lightblue')

lines(rollapply(df_lect_sub[,'pm.10..ug.m3.'], 
          FUN=function(x) mean(x, na.rm=TRUE), width=20, fill=NA),
     type='l', col= 1, lwd= 2)
legend(200,155, legend=c("minute data", "rolling mean 20 mins"), 
       col=c('lightblue',1), lty= 1, cex=1, lwd=2)
box()

```

#### **Doing some basic statistics on the datasets**

In this section we start to calculate some statistics for the datasets. Let us start by calculating the mean PM10 mass concentration during the entire dataset:
```{r basic statistics}

mean(df_lect[,"pm.10..ug.m3."], na.rm=TRUE)
```

Maybe we only want to calculate the mean between noon and 11 PM on 2 December:
```{r calculate mean at set times}
mean(df_lect[which(df_lect$date..UTC.=='2020-12-02 12:00:00'):which(df_lect$date..UTC.=='2020-12-02 23:00:00'), 'pm.10..ug.m3.'], na.rm=TRUE)

```

```{r  Summary  statistics}
summary(df_lect['NO2..ppb.'], na.rm=TRUE)
```
